import gradio as gr
import requests
import json
import time
import os
import uuid

from service.chat_api import logger


def get_available_models():
    """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    try:
        response = requests.get("http://127.0.0.1:8116/api/v1/models")
        if response.status_code == 200:
            data = response.json()
            return data.get("llm_model_names", ["qwen-14b"])  # é»˜è®¤è¿”å›qwen-14b
        else:
            logger.info(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {response.status_code}")
            return ["qwen-14b"]
    except Exception as e:
        logger.info(f"è·å–æ¨¡å‹åˆ—è¡¨å‡ºé”™: {str(e)}")
        return ["qwen-14b"]

def query_api(session_id, conversation_history, sys_query, uploaded_files, file_names, kb_names, kb_token,
              top_k, top_n, key_weight, system_prompt, input_body, output_body,
              temperature, model_name, task_type, force_ocr=False,kb_type = "ufrag"):
    """å‘APIå‘é€è¯·æ±‚å¹¶å¤„ç†æµå¼å“åº”"""
    url = "http://127.0.0.1:8116/api/v1/chat-conversation"  # æ³¨æ„ä½¿ç”¨æ–°çš„ç«¯ç‚¹
    headers = {"accept": "text/event-stream"}
    # å¦‚æœæ²¡æœ‰ä¼šè¯IDï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
    if not session_id:
        session_id = str(uuid.uuid4())
        logger.info(f"åˆ›å»ºæ–°ä¼šè¯: {session_id}")
    # å°†kb_nameså’Œfile_namesè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²åˆ—è¡¨
    kb_names_list = [name.strip() for name in kb_names.split(",") if name.strip()]
    file_names_list = [name.strip() for name in file_names.split(",") if name.strip()]
    # æ›´æ–°å¯¹è¯å†å²
    if not conversation_history:
        conversation_history = []
    # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    # conversation_history.append({
    #     "role": "user",
    #     "content": sys_query,
    #     "session_id": session_id
    # })
    # å‡†å¤‡è¡¨å•æ•°æ®
    data = {
        "sys_query": sys_query,
        "file_names": json.dumps(file_names_list),
        "knowledge_base_type":kb_type,
        "kb_names": json.dumps(kb_names_list),
        "top_k": top_k,
        "top_n": top_n,
        "key_weight": key_weight,
        "kb_token":kb_token,
        "system_prompt": system_prompt,
        "input_body": input_body,
        "output_body": output_body,
        "temperature": temperature,
        "model_name": model_name,
        "task_type": task_type,
        "session_id": session_id,
        "conversation_history": json.dumps(conversation_history),
        "force_ocr": str(force_ocr)
    }
    # å‡†å¤‡æ–‡ä»¶
    file_objects = []
    try:
        files = []
        if uploaded_files:
            for file_path in uploaded_files:
                file_name = os.path.basename(file_path.name)
                # æ‰“å¼€æ–‡ä»¶å¹¶ä¿å­˜æ–‡ä»¶å¯¹è±¡ä»¥ä¾¿ä¹‹åå…³é—­
                file_obj = open(file_path.name, "rb")
                file_objects.append(file_obj)
                files.append(("files", (file_name, file_obj, "application/octet-stream")))
        response = requests.post(url, headers=headers, data=data, files=files, stream=True)
        # æ£€æŸ¥å“åº”çŠ¶æ€
        if response.status_code != 200:
            return session_id, conversation_history, f"Error: Server returned status code {response.status_code}"
        full_answer = ""
        current_file = None
        file_processing = False
        summary_generation = False
        final_answer_generation = False
        final_answer = ""
        json_conversion = False
        # ä½¿ç”¨yieldæ¥å®ç°æµå¼è¾“å‡º
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data:'):
                    try:
                        event_data = json.loads(line[5:].strip())
                        event_type = event_data.get("events")
                        # å¤„ç†ä¸åŒç±»å‹çš„äº‹ä»¶
                        if event_type == "node_started":
                            node_name = event_data.get("node")
                            message = event_data.get("message", "")
                            # æ·»åŠ äº‹ä»¶èµ·å§‹æ ‡è®°å’Œæ¢è¡Œ
                            if node_name == "query_enhancement":
                                full_answer += "\n\nğŸš€\n" + message  # æ›¿æ¢ã€æŸ¥è¯¢ä¼˜åŒ–å¼€å§‹ã€‘
                            elif node_name == "multi_file_processing":
                                full_answer += "\n\nğŸ“‚\n" + message  # æ›¿æ¢ã€å¤šæ–‡ä»¶å¤„ç†å¼€å§‹ã€‘
                            elif node_name == "file_processing":
                                file_name = event_data.get("file", "æœªçŸ¥æ–‡ä»¶")
                                current_file = file_name
                                file_processing = True
                                full_answer += f"\n\nğŸ“„ {file_name}\n" + message  # æ›¿æ¢ã€å¼€å§‹å¤„ç†æ–‡ä»¶: {file_name}ã€‘
                            elif node_name == "summary_generation":
                                file_name = event_data.get("file", "æœªçŸ¥æ–‡ä»¶")
                                current_file = file_name
                                summary_generation = True
                                full_answer += f"\n\nğŸ“ {file_name}\n" + message  # æ›¿æ¢ã€å¼€å§‹ç”Ÿæˆæ‘˜è¦: {file_name}ã€‘
                            elif node_name == "final_answer":
                                final_answer_generation = True
                                full_answer += "\n\nâœ…\n" + message  # æ›¿æ¢ã€å¼€å§‹ç”Ÿæˆæœ€ç»ˆå›ç­”ã€‘
                            elif node_name == "convert_to_json":
                                json_conversion = True
                                full_answer += "\n\nğŸ”„\n" + message  # æ›¿æ¢ã€å¼€å§‹è½¬æ¢ä¸ºJSONã€‘
                            yield session_id, conversation_history, full_answer, final_answer
                        elif event_type == "node_finished":
                            node_name = event_data.get("node")
                            message = event_data.get("message", "")
                            completed = event_data.get("completed", "")
                            # æ·»åŠ äº‹ä»¶ç»“æŸæ ‡è®°å’Œæ¢è¡Œ
                            if node_name == "query_enhancement":
                                full_answer += "\nğŸš€å®Œæˆ\n" + message  # æ›¿æ¢ã€æŸ¥è¯¢ä¼˜åŒ–å®Œæˆã€‘
                            elif node_name == "multi_file_processing":
                                full_answer += "\nğŸ“‚å®Œæˆ\n" + message  # æ›¿æ¢ã€å¤šæ–‡ä»¶å¤„ç†å®Œæˆã€‘
                            elif node_name == "file_processing":
                                file_processing = False
                                full_answer += "\nğŸ“„å¤„ç†å®Œæˆ\n" + message  # æ›¿æ¢ã€æ–‡ä»¶å¤„ç†å®Œæˆã€‘
                            elif node_name == "summary_generation":
                                summary_generation = False
                                full_answer += "\nğŸ“ç”Ÿæˆå®Œæˆ\n" + message  # æ›¿æ¢ã€æ‘˜è¦ç”Ÿæˆå®Œæˆã€‘
                            elif node_name == "final_answer":
                                final_answer_generation = False
                                full_answer += "\nâœ…ç”Ÿæˆå®Œæˆ\n" + message  # æ›¿æ¢ã€æœ€ç»ˆå›ç­”ç”Ÿæˆå®Œæˆã€‘
                                # å°†å®Œæ•´çš„å›ç­”æ·»åŠ åˆ°å¯¹è¯å†å²
                                if completed:
                                    final_answer = completed
                                # yield session_id, conversation_history, full_answer
                            elif node_name == "convert_to_json":
                                json_conversion = False
                                full_answer += "\nğŸ”„è½¬æ¢å®Œæˆ\n" + message  # æ›¿æ¢ã€JSONè½¬æ¢å®Œæˆã€‘
                            yield session_id, conversation_history, full_answer, final_answer
                        elif event_type == "node_progress":
                            node_name = event_data.get("node", "")
                            message = event_data.get("message", "")
                            progress = event_data.get("progress", 0.0)
                            full_answer += f"\nã€è¿›åº¦æ›´æ–° - {node_name}ã€‘: {message}ï¼ˆè¿›åº¦: {progress:.1f}%ï¼‰"
                            yield session_id, conversation_history, full_answer, final_answer
                        elif event_type == "documents_retrieved":
                            file_name = event_data.get("file", "æœªçŸ¥æ–‡ä»¶")
                            full_answer += f"\nã€å·²æ£€ç´¢æ–‡ä»¶: {file_name}ã€‘\n"
                            # å¯ä»¥æ·»åŠ æ–‡æ¡£è¯¦æƒ…å¦‚æœéœ€è¦
                            docs = event_data.get("documents", [])
                            if docs:
                                full_answer += f"æ£€ç´¢åˆ° {len(docs)} ä¸ªæ–‡æ¡£ç‰‡æ®µ\n"
                            yield session_id, conversation_history, full_answer, final_answer
                        elif event_type == "message":
                            if "answer" in event_data:
                                token = event_data["answer"]
                                file_name = event_data.get("file", "")
                                # æ ¹æ®å½“å‰å¤„ç†é˜¶æ®µæ·»åŠ æ ‡è®°
                                if file_name and file_name != current_file and summary_generation:
                                    current_file = file_name
                                    full_answer += f"\nã€æ–‡ä»¶æ‘˜è¦: {file_name}ã€‘\n"
                                full_answer += token
                                yield session_id, conversation_history, full_answer, final_answer
                                time.sleep(0.01)  # çŸ­æš‚æš‚åœä»¥å…è®¸UIæ›´æ–°
                        elif event_type == "error":
                            full_answer += f"\n\nã€é”™è¯¯ã€‘\n{event_data.get('message', 'Unknown error')}"
                            yield session_id, conversation_history, full_answer, final_answer
                        elif event_type == "complete":
                            full_answer += "\n\nã€å¤„ç†å®Œæˆã€‘"
                            yield session_id, conversation_history, full_answer, final_answer
                    except json.JSONDecodeError:
                        full_answer += f"\n\nã€é”™è¯¯ã€‘\nInvalid JSON response: {line[5:].strip()}"
                        yield session_id, conversation_history, full_answer, final_answer
    finally:
        # ç¡®ä¿æ‰€æœ‰æ–‡ä»¶éƒ½è¢«å…³é—­
        for file_obj in file_objects:
            try:
                file_obj.close()
            except:
                pass

# æ ¼å¼åŒ–å¯¹è¯å†å²ä¸ºå¯è¯»æ–‡æœ¬
def format_conversation(conversation_history):
    if not conversation_history:
        return ""

    formatted_text = ""
    for msg in conversation_history:
        role = msg.get("role", "")
        content = msg.get("content", "")

        if role == "user":
            formatted_text += f"ğŸ§‘ ç”¨æˆ·: {content}\n\n"
        elif role == "assistant":
            formatted_text += f"ğŸ¤– åŠ©æ‰‹: {content}\n\n"
        elif role == "system":
            formatted_text += f"ğŸ”§ ç³»ç»Ÿ: {content}\n\n"

    return formatted_text

# å…¨å±€çŠ¶æ€å˜é‡ï¼Œç”¨äºæ§åˆ¶ç”Ÿæˆè¿‡ç¨‹
stop_generation = gr.State(False)

# é‡è¯•åŠŸèƒ½ - é‡æ–°å‘é€ä¸Šä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
def retry_last_query(session_id, conversation_history, uploaded_files, file_names, kb_names, kb_token, top_k, top_n, key_weight, system_prompt, input_body, output_body, temperature, model_name, task_type, max_turns, force_ocr):
    # é‡ç½®åœæ­¢æ ‡å¿—
    stop_flag = False

    # ç¡®ä¿æœ‰å¯¹è¯å†å²
    if not conversation_history:
        return session_id, conversation_history, [], "", stop_flag

    # æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
    last_user_msg = None
    for msg in reversed(conversation_history):
        if msg["role"] == "user":
            last_user_msg = msg["content"]
            break

    if not last_user_msg:
        return session_id, conversation_history, [], "", stop_flag

    # å¦‚æœæœ€åä¸€æ¡æ˜¯åŠ©æ‰‹æ¶ˆæ¯ï¼Œåˆ™ç§»é™¤å®ƒ
    if conversation_history and conversation_history[-1]["role"] == "assistant":
        conversation_history = conversation_history[:-1]

    # é‡æ–°ç”Ÿæˆå“åº”
    for result in submit_query(
            session_id, conversation_history, last_user_msg, uploaded_files,
            file_names, kb_names, kb_token, top_k, top_n, key_weight,
            system_prompt, input_body, output_body, temperature,
            model_name, task_type, max_turns, force_ocr,None
    ):
        yield result

# åœæ­¢ç”Ÿæˆ
def stop_generation_fn():
    return True

# é‡ç½®åœæ­¢æ ‡å¿—
def reset_stop_flag():
    return False

css = """
#user_input {margin-right: 5px !important;}
.compact-btn {min-width: 20px !important; padding: 0 5px !important;}
"""
with gr.Blocks(theme=gr.themes.Base(),css=css) as demo:
    gr.Markdown("# deepseekä»£ç† - å¤šè½®å¯¹è¯ç‰ˆæœ¬")
    # å­˜å‚¨ä¼šè¯çŠ¶æ€
    session_id = gr.State("")
    conversation_history = gr.State([])
    with gr.Row():
        with gr.Column(scale=3):
            # ç»Ÿä¸€çš„èŠå¤©ç•Œé¢ - ä½¿ç”¨Chatbotç»„ä»¶æ›¿ä»£åˆ†å¼€çš„æ–‡æœ¬æ¡†
            chatbot = gr.Chatbot(
                label="å¯¹è¯ç•Œé¢",
                height=500,
                elem_id="chatbox"
            )
            # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
            with gr.Row(equal_height=True):
                sys_query = gr.Textbox(
                    label="ç”¨æˆ·è¾“å…¥",
                    placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
                    lines=2,
                    max_lines=5,
                    scale=5,
                    container=False,
                    elem_id="user_input"
                )
                with gr.Column(scale=1, min_width=150, elem_id="chat_controls"):
                    submit_btn = gr.Button("å‘é€", variant="primary", size="sm")
                    with gr.Row():
                        retry_btn = gr.Button("â†»", variant="secondary", size="sm",
                                              elem_classes="compact-btn")
                        stop_btn = gr.Button("â– ", variant="stop", size="sm",
                                             elem_classes="compact-btn")
        with gr.Column(scale=2):
            # ç³»ç»Ÿè®¾ç½®
            with gr.Accordion("ç³»ç»Ÿè®¾ç½®", open=False):
                system_prompt = gr.Textbox(
                    label="ç³»ç»Ÿæç¤ºè¯",
                    placeholder="å¯é€‰ç³»ç»Ÿæç¤ºè¯...",
                    lines=3,
                    value="ä»æä¾›çš„å†…å®¹æ€»ç»“åçš„æ–‡æ¡£ä¸­è·å–ç›¸åº”çš„çŸ¥è¯†æ¥å‡†ç¡®å›ç­”ç”¨æˆ·çš„é—®é¢˜æˆ–è€…å®Œæˆç”¨æˆ·çš„éœ€æ±‚\nå¦‚æœä½¿ç”¨åŸæ–‡æ¡£è¾“å‡ºï¼Œéœ€è¦æ³¨æ„è¾“å‡ºæ ¼å¼çš„è§„æ•´å’Œè§†è§‰çš„ç¾è§‚ï¼Œä¼˜å…ˆæ•´ç†ä¸ºè¡¨æ ¼ç­‰å½¢å¼ä½¿å¾—è¾“å‡ºçš„ç»“æœç¾è§‚ã€‚\nå¦‚æœæœªæä¾›ç›¸åº”çš„æ–‡æ¡£ï¼Œæˆ–è€…æä¾›çš„æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œè¯·å›ç­”æœªæ‰¾åˆ°ç­”æ¡ˆï¼Œå¹¶å›ç­”ä¸ºä»€ä¹ˆã€‚"
                )
                # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
                available_models = get_available_models()
                model_name = gr.Dropdown(
                    choices=available_models,
                    value=available_models[0] if available_models else "qwen-14b",
                    label="é€‰æ‹©æ¨¡å‹"
                )
                temperature = gr.Slider(
                    minimum=0,
                    maximum=1,
                    value=0.1,
                    step=0.1,
                    label="æ¸©åº¦"
                )
                # æ–°å¢ï¼šå¯¹è¯è½®æ•°æ§åˆ¶
                max_turns = gr.Slider(
                    minimum=1,
                    maximum=10,
                    value=5,
                    step=1,
                    label="æœ€å¤§å¯¹è¯è½®æ•°"
                )
                task_type = gr.Dropdown(
                    choices=["default", "sql","oa_invoice_validate","oa_invoice_validate_raw","summary_extract","uav_weather_assistant"],
                    value="default",
                    label="ä»»åŠ¡ç±»å‹"
                )
                # ä¼šè¯ç®¡ç†æŒ‰é’®
                with gr.Row():
                    new_chat_btn = gr.Button("æ–°å¯¹è¯", variant="secondary")
                    clear_history_btn = gr.Button("æ¸…ç©ºå†å²", variant="secondary")
            # çŸ¥è¯†åº“é…ç½®
            with gr.Accordion("çŸ¥è¯†åº“é…ç½®", open=True):
                # æ–°å¢ï¼šçŸ¥è¯†åº“ç±»å‹é€‰æ‹©
                kb_type = gr.Radio(
                    choices=["ufrag", "ragflow"],
                    value="ragflow",
                    label="çŸ¥è¯†åº“ç±»å‹"
                )
                kb_names = gr.Textbox(
                    label="çŸ¥è¯†åº“åç§°",
                    placeholder="è¾“å…¥çŸ¥è¯†åº“åç§°ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”",
                    value="nianbaomix00,nianbaomix00_index"
                )
                kb_token = gr.Textbox(
                    label="çŸ¥è¯†åº“Token",
                    placeholder="è¾“å…¥çŸ¥è¯†åº“è®¿é—®tokenï¼ˆå¯é€‰ï¼‰",
                    value=""
                )
                file_names = gr.Textbox(
                    label="æ–‡ä»¶åç§°",
                    placeholder="è¾“å…¥æ–‡ä»¶åç§°ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”",
                    value="åˆ›ä¸¾ç§‘æŠ€ï¼š2024å¹´åŠå¹´åº¦æŠ¥å‘Š.PDF,é•¿äº®ç§‘æŠ€ï¼š2024å¹´åŠå¹´åº¦æŠ¥å‘Š.PDF"
                )
                uploaded_files = gr.File(
                    label="ä¸Šä¼ æ–‡ä»¶",
                    file_count="multiple"
                )
                force_ocr = gr.Checkbox(
                    label="å¼ºåˆ¶OCRå¤„ç†",
                    value=False,
                    info="å¯ç”¨OCRå¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"
                )
            # æ£€ç´¢å‚æ•°
            with gr.Accordion("æ£€ç´¢å‚æ•°", open=False):
                top_k = gr.Slider(
                    minimum=1,
                    maximum=55,
                    value=45,
                    step=1,
                    label="Top K"
                )
                top_n = gr.Slider(
                    minimum=1,
                    maximum=7,
                    value=3,
                    step=1,
                    label="Top N"
                )
                key_weight = gr.Slider(
                    minimum=0,
                    maximum=1,
                    value=0.8,
                    step=0.1,
                    label="å…³é”®è¯æƒé‡"
                )
            # é¢å¤–æ•°æ®é…ç½®
            with gr.Accordion("é¢å¤–æ•°æ®é…ç½®", open=False):
                input_body = gr.Textbox(
                    label="æ•°æ®èµ„äº§apiæ¥å£æ•°æ®",
                    value="default",
                    placeholder="è¾“å…¥ä½“æ ¼å¼..."
                )
                output_format = gr.Textbox(
                    label="è¾“å‡ºä½“æ ¼å¼ (JSON)",
                    placeholder='',
                    lines=2,
                    value=""
                )
    # åˆ›å»ºæ–°å¯¹è¯
    def create_new_chat():
        return str(uuid.uuid4()), [], [], None
    # æ¸…ç©ºå†å²ä½†ä¿ç•™ä¼šè¯ID
    def clear_chat_history(session_id):
        return session_id, [], [], None
    # å¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶æˆªæ–­å†å²ä»¥ä¿æŒåœ¨æœ€å¤§è½®æ•°å†…
    # æ›´æ–°èŠå¤©ç•Œé¢
    def update_chatbot(conversation):
        # è½¬æ¢conversation_historyä¸ºchatbotæ ¼å¼ [(user, assistant), ...]
        chatbot_pairs = []
        i = 0
        while i < len(conversation):
            if conversation[i]['role'] == 'user':
                user_msg = conversation[i]['content']
                # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªåŠ©æ‰‹æ¶ˆæ¯
                j = i + 1
                while j < len(conversation) and conversation[j]['role'] != 'assistant':
                    j += 1
                # å¦‚æœæ‰¾åˆ°åŠ©æ‰‹æ¶ˆæ¯ï¼Œåˆ™æ·»åŠ å¯¹è¯å¯¹
                if j < len(conversation) and conversation[j]['role'] == 'assistant':
                    assistant_msg = conversation[j]['content']
                    chatbot_pairs.append([user_msg, assistant_msg])
                    i = j + 1  # è·³è¿‡å·²å¤„ç†çš„åŠ©æ‰‹æ¶ˆæ¯
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŠ©æ‰‹æ¶ˆæ¯ï¼Œæ·»åŠ åªæœ‰ç”¨æˆ·æ¶ˆæ¯çš„å¯¹è¯å¯¹
                    chatbot_pairs.append([user_msg, None])
                    i += 1
            else:
                # è·³è¿‡éç”¨æˆ·æ¶ˆæ¯
                i += 1
        return chatbot_pairs
    # å¤„ç†ç”¨æˆ·æŸ¥è¯¢å’Œæ„å»ºå“åº”
    def submit_query(session_id, conversation_history, query, uploaded_files, file_names, kb_names, kb_token, top_k, top_n, key_weight, system_prompt, input_body, output_body, temperature, model_name, task_type, max_turns, force_ocr, kb_type):
        # å°†ç”¨æˆ·æŸ¥è¯¢æ·»åŠ åˆ°å¯¹è¯å†å²
        updated_conversation = conversation_history.copy()
        if not updated_conversation or updated_conversation[-1]['role'] != 'user' or updated_conversation[-1]['content'] != query:
            updated_conversation.append({"role": "user", "content": query})
        # æ›´æ–°Chatbotæ˜¾ç¤ºï¼ˆåªæœ‰ç”¨æˆ·æ¶ˆæ¯ï¼‰
        chatbot_display = update_chatbot(updated_conversation)
        # è°ƒç”¨APIè·å–å›å¤
        response = ""
        final_answer = ""  # ç”¨äºå­˜å‚¨æœ€ç»ˆç­”æ¡ˆ
        # ä½¿ç”¨ try/finally ç¡®ä¿å³ä½¿å‘ç”Ÿé”™è¯¯ä¹Ÿèƒ½æ›´æ–°UI
        try:
            for session_id, updated_history, api_response, api_final_answer in query_api(
                    session_id, updated_conversation, query, uploaded_files,
                    file_names, kb_names, kb_token, top_k, top_n, key_weight,
                    system_prompt, input_body, output_body, temperature,
                    model_name, task_type, force_ocr, kb_type
            ):
                # æ›´æ–°å“åº”æ–‡æœ¬å’Œæœ€ç»ˆç­”æ¡ˆ
                response = api_response
                if api_final_answer:  # å¦‚æœæœ‰æœ€ç»ˆç­”æ¡ˆï¼Œæ›´æ–°å®ƒ
                    final_answer = api_final_answer
                # åˆ›å»ºä¸´æ—¶å¯¹è¯å†å²ç”¨äºæ˜¾ç¤º
                temp_history = updated_conversation.copy()
                # æ·»åŠ æˆ–æ›´æ–°åŠ©æ‰‹å›å¤ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
                if temp_history and temp_history[-1]['role'] == 'user':
                    # å¦‚æœæœ€åä¸€æ¡æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œæ·»åŠ æ–°çš„åŠ©æ‰‹æ¶ˆæ¯ï¼ˆæ˜¾ç¤ºå®Œæ•´æµç¨‹ï¼‰
                    temp_history.append({"role": "assistant", "content": response})
                elif temp_history and temp_history[-1]['role'] == 'assistant':
                    # å¦‚æœæœ€åä¸€æ¡å·²ç»æ˜¯åŠ©æ‰‹æ¶ˆæ¯ï¼Œæ›´æ–°å†…å®¹ï¼ˆæ˜¾ç¤ºå®Œæ•´æµç¨‹ï¼‰
                    temp_history[-1]['content'] = response
                # æ›´æ–°UI
                chatbot_display = update_chatbot(temp_history)
                yield session_id, temp_history, chatbot_display, "",None
                time.sleep(0.05)  # å°å»¶è¿Ÿç¡®ä¿UIæ›´æ–°
            # æœ€ç»ˆæ›´æ–°å¯¹è¯å†å²ï¼ˆä¿å­˜æœ€ç»ˆç­”æ¡ˆï¼‰
            if final_answer:  # å¦‚æœæœ‰æœ€ç»ˆç­”æ¡ˆï¼Œä½¿ç”¨å®ƒ
                if updated_conversation and updated_conversation[-1]['role'] == 'user':
                    updated_conversation.append({"role": "assistant", "content": final_answer})
                elif updated_conversation and updated_conversation[-1]['role'] == 'assistant':
                    updated_conversation[-1]['content'] = final_answer
            else:  # å¦‚æœæ²¡æœ‰æœ€ç»ˆç­”æ¡ˆï¼Œä½¿ç”¨å®Œæ•´å“åº”
                if updated_conversation and updated_conversation[-1]['role'] == 'user':
                    updated_conversation.append({"role": "assistant", "content": response})
                elif updated_conversation and updated_conversation[-1]['role'] == 'assistant':
                    updated_conversation[-1]['content'] = response
            # é™åˆ¶å†å²å¯¹è¯è½®æ•°
            max_messages = max_turns * 2  # æ¯è½®åŒ…å«ç”¨æˆ·å’ŒåŠ©æ‰‹å„ä¸€æ¡æ¶ˆæ¯
            if len(updated_conversation) > max_messages:
                # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ï¼‰å’Œæœ€è¿‘çš„max_messagesæ¡æ¶ˆæ¯
                system_messages = [msg for msg in updated_conversation if msg["role"] == "system"]
                recent_messages = updated_conversation[-max_messages:]
                updated_conversation = system_messages + recent_messages
        finally:
            # æœ€ç»ˆUIæ›´æ–°ï¼ˆä½¿ç”¨æœ€ç»ˆä¿å­˜çš„å¯¹è¯å†å²ï¼‰
            chatbot_display = update_chatbot(updated_conversation)
            yield session_id, updated_conversation, chatbot_display, "", None  # æ·»åŠ Noneæ¸…ç©ºä¸Šä¼ æ–‡ä»¶
    # åœæ­¢æŒ‰é’®äº‹ä»¶
    stop_btn.click(
        fn=stop_generation_fn,
        inputs=[],
        outputs=[stop_generation]
    )
    # æäº¤æŸ¥è¯¢äº‹ä»¶
    submit_event = submit_btn.click(
        fn=submit_query,
        inputs=[
            session_id,
            conversation_history,
            sys_query,
            uploaded_files,
            file_names,
            kb_names,
            kb_token,
            top_k,
            top_n,
            key_weight,
            system_prompt,
            input_body,
            output_format,
            temperature,
            model_name,
            task_type,
            max_turns,
            force_ocr,
            kb_type  # æ·»åŠ kb_typeå‚æ•°
        ],
        outputs=[session_id, conversation_history, chatbot, sys_query, uploaded_files]
    )
    # åˆ›å»ºæ–°å¯¹è¯
    new_chat_btn.click(
        fn=create_new_chat,
        inputs=[],
        outputs=[session_id, conversation_history, chatbot, uploaded_files]
    )
    # æ¸…ç©ºå†å²
    clear_history_btn.click(
        fn=clear_chat_history,
        inputs=[session_id],
        outputs=[session_id, conversation_history, chatbot, uploaded_files]
    )
    # Enteré”®æäº¤
    sys_query.submit(
        fn=submit_query,
        inputs=[
            session_id,
            conversation_history,
            sys_query,
            uploaded_files,
            file_names,
            kb_names,
            kb_token,
            top_k,
            top_n,
            key_weight,
            system_prompt,
            input_body,
            output_format,
            temperature,
            model_name,
            task_type,
            max_turns,
            force_ocr,
            kb_type  # æ·»åŠ kb_typeå‚æ•°
        ],
        outputs=[session_id, conversation_history, chatbot, sys_query,uploaded_files]
    )
# å¯åŠ¨Gradioåº”ç”¨
if __name__ == "__main__":
    demo.queue().launch(server_name="0.0.0.0", server_port=7862)
